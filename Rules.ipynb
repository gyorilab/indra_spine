{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76b754-0bb1-4370-8022-77b3069883f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indra_cogex.sources.odinson.grammars import Rule\n",
    "from indra_cogex.sources.odinson.client import process_rules\n",
    "import gilda\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from gilda.process import normalize\n",
    "from tqdm.auto import tqdm\n",
    "from pyobo.gilda_utils import get_gilda_terms\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import textwrap\n",
    "import random\n",
    "import difflib\n",
    "\n",
    "import indra_cogex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d10c26-6443-4462-b48d-0e7c3a2aa5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grounder with spine terms\n",
    "import spine_ner\n",
    "grounder = spine_ner.grounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0be87f-00ea-4671-a97b-0112a343953a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create rule sets\n",
    "from itertools import product\n",
    "import rule_gen \n",
    "\n",
    "brain_regions = rule_gen.brain_regions\n",
    "phenotypes = rule_gen.phenotypes\n",
    "\n",
    "br_rules = []\n",
    "ph_rules = []\n",
    "\n",
    "br_br_rules = [rule_gen.create_br_br_rules(br_1,br_2) for br_1,br_2 in product(brain_regions, brain_regions)]\n",
    "\n",
    "br_ph_rules = [rule_gen.create_br_ph_rules(br,ph) for br,ph in product(brain_regions, phenotypes)]\n",
    "\n",
    "for rule_set in br_br_rules:\n",
    "    for individual_rule in rule_set:\n",
    "        br_rules.append(individual_rule)\n",
    "\n",
    "for rule_set in br_ph_rules:\n",
    "    for individual_rule in rule_set:\n",
    "        ph_rules.append(individual_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46396916-eed7-4c95-8994-7fb0b74a1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rule_gen\n",
    "br_rules = rule_gen.permutations()['br']\n",
    "ph_rules = rule_gen.permutations()['ph']\n",
    "print(len(br_rules))\n",
    "print(len(ph_rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728f4f0-5e73-4532-99a6-1a3eb343fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all sets of words to be excluded\n",
    "#import stop_words \n",
    "\n",
    "sw_nltk = stopwords.words('english')\n",
    "#false_phrases = stop_words.false_phrases\n",
    "#exclude_words = stop_words.exclude_words\n",
    "\n",
    "with open('exclude_words.txt', 'r') as file:\n",
    "    exclude_words = [line.strip() for line in file if line.strip()]\n",
    "    \n",
    "with open('false_phrases.txt', 'r') as file:\n",
    "    false_phrases = [line.strip() for line in file if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b860d51b-148f-41eb-ae04-b427bb787ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the set of brain region-brain region relations\n",
    "relations = []\n",
    "\n",
    "# Go through each rule and make it a rule object\n",
    "for rule_text in tqdm(br_rules):\n",
    "    rule = Rule(\"anatomical connection\", \"Exp\", \"basic\", rule_text)\n",
    "    #Make sure it is a functional Odinson rule\n",
    "    try:\n",
    "        rule_output = process_rules([rule],\"http://localhost:9000\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('failed', rule)\n",
    "        print(e)\n",
    "        \n",
    "    # Get the start and end characters for each term pulled out by the rule\n",
    "    for sentence in rule_output['mentions']:\n",
    "        relation = ()\n",
    "        words = sentence['words']\n",
    "        string_words = ' '.join(words)\n",
    "        for element in sentence['match']:  \n",
    "            for entity in element['namedCaptures']:\n",
    "                start = entity['capturedMatch']['start']\n",
    "                end = entity['capturedMatch']['end']\n",
    "                # Remove stop words\n",
    "                processed_term = [word for word in words[start:end] if word.lower() not in sw_nltk]\n",
    "                word = ' '.join(processed_term)\n",
    "                if word.lower() not in exclude_words:                   \n",
    "                    # Create tuples with curies for terms that can be grounded\n",
    "                    spine_scored_match = grounder.ground(word)\n",
    "                    gilda_scored_match = gilda.ground(word)\n",
    "    \n",
    "                    if len(spine_scored_match)>0:\n",
    "                        best_curie = spine_scored_match[0].term.get_curie()\n",
    "                    elif len(gilda_scored_match)>0:\n",
    "                        best_curie = gilda_scored_match[0].term.get_curie()\n",
    "                    else:\n",
    "                        best_curie = None\n",
    "\n",
    "                    if word != '' and best_curie != None:\n",
    "                        relation += ((best_curie, word),)  \n",
    "        if len(relation) > 1 and relation not in relations and relation[0][1] != relation[1][1]:\n",
    "            relations.append(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038b979-e913-46ce-b24a-30814d12dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4afd96-9f6f-4496-98e1-c7275781f8f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the set of brain region-phenotype relations\n",
    "ph_relations = []\n",
    "# Go through each rule and make it a rule object\n",
    "for rule_text in tqdm(ph_rules):\n",
    "    rule = Rule(\"phenotype\", \"Exp\", \"basic\", rule_text)\n",
    "    #Make sure it is a functional Odinson rule\n",
    "    try:\n",
    "        rule_output = process_rules([rule],\"http://localhost:9000\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('failed', rule)\n",
    "        print(e)\n",
    "\n",
    "    # Get the start and end characters for each term pulled out by the rule\n",
    "    for sentence in rule_output['mentions']:\n",
    "        relation = ()\n",
    "        words = sentence['words']\n",
    "        string_words = ' '.join(words)\n",
    "        for element in sentence['match']:\n",
    "            for entity in element['namedCaptures']:\n",
    "                start = entity['capturedMatch']['start']\n",
    "                end = entity['capturedMatch']['end']\n",
    "                # Remove stop words\n",
    "                processed_term = [word for word in words[start:end] if word.lower() not in sw_nltk]\n",
    "                word = ' '.join(processed_term)\n",
    "                if word.lower() not in exclude_words:                   \n",
    "                    # Create tuples with curies for terms that can be grounded\n",
    "                    spine_scored_match = grounder.ground(word)\n",
    "                    gilda_scored_match = gilda.ground(word)\n",
    "    \n",
    "                    if len(gilda_scored_match)>0:\n",
    "                        best_curie = gilda_scored_match[0].term.get_curie()\n",
    "                    elif len(spine_scored_match)>0:\n",
    "                        best_curie = spine_scored_match[0].term.get_curie()\n",
    "                    else:\n",
    "                        best_curie = None\n",
    "\n",
    "                    if word != '' and best_curie != None:\n",
    "                        relation += ((best_curie, word),)  \n",
    "        if len(relation) > 1 and relation not in ph_relations and relation[0][1] != relation[1][1]:\n",
    "            ph_relations.append(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552251b3-03d9-41d3-9950-046cf9c25fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ph_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c3b7c-6612-47be-b4a6-82feeef90a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interaction map of relationships between terms\n",
    "import networkx as nx\n",
    "import pygraphviz as pgv\n",
    "import matplotlib.pyplot as plt\n",
    "G = nx.Graph()\n",
    "plt.figure(figsize=(50,50))\n",
    "G.add_edges_from(relations, len=4,color='red')\n",
    "G.add_edges_from(ph_relations, len=4,color='blue')\n",
    "\n",
    "edge_colors = [G.edges[edge]['color'] for edge in G.edges]\n",
    "\n",
    "pos = nx.nx_agraph.graphviz_layout(G, prog='neato')\n",
    "labels = {}\n",
    "for k in pos.keys():\n",
    "    labels[k] = k[1]\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_size=100, node_color='white', node_shape='o')\n",
    "nx.draw_networkx_edges(G, pos, width=1.0, edge_color=edge_colors, style='solid')\n",
    "labels = nx.draw_networkx_labels(G, pos, labels = labels, font_size=8, font_color='k', font_family='sans-serif', font_weight='normal')\n",
    "\n",
    "print()\n",
    "plt.savefig(\"X.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
